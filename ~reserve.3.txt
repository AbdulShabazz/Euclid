

		// Prevent next round call loops to improve Performance
		std::unordered_map<BigInt128_t,
		std::unordered_map<BigInt128_t, bool>>

		CallHistory{},
		NextRoundCallHistory{};

		//CallHistory.reserve (100'000); // (Max expected elements for Performance)
//
#include <iostream>
#include <vector>
#include <string>
#include <unordered_set>
#include <unordered_map>
#include <cstdlib>
#include <chrono>
#include <initializer_list>
    
std::vector<std::string> TraceCallStackStdStrVec {"EuclidProver"};
    
void __stdlog__(const std::initializer_list<std::string>& msg, const bool AddNewlineFlag = true)
{
	auto it = msg.begin();
	auto IT = msg.end();
	std::cout << *it;
	++it; // Advance the iterator by 1 position //
	for (it; it != IT; ++it)
	{
		std::cout << " " << *it;
	}
	if (AddNewlineFlag)
		std::cout << std::endl;
};

void __stdtracein__(const std::string& msg)
{
	TraceCallStackStdStrVec.emplace_back (msg);
	const std::size_t I = TraceCallStackStdStrVec.size ();
	std::cout << TraceCallStackStdStrVec[0];
	for (std::size_t i = 1; i < I; ++i)
	{
		std::cout << " >> " << TraceCallStackStdStrVec[i];
	}
	std::cout << std::endl;
};

void __stdtraceout__(const std::string& msg)
{
	TraceCallStackStdStrVec.pop_back ();
	const std::size_t I = TraceCallStackStdStrVec.size ();
	std::string buff{TraceCallStackStdStrVec[0]};
	for (std::size_t i = 1; i < I; ++i)
	{
	    buff.append(" >> " + TraceCallStackStdStrVec[i]);
	}
	std::cout << buff << " << " << msg << std::endl;
	std::cout << buff << std::endl;
};

int main()
{
    constexpr std::size_t LHS {};
    constexpr std::size_t RHS {1};
    constexpr std::size_t guid_UInt64 {2};
	constexpr std::size_t last_UInt64 {3};
	constexpr std::size_t ProofStack_UInt64 {4};
	
	std::unordered_map<
	/*BigInt128_t*/
	std::size_t,
	std::unordered_map<
	/*BigInt128_t*/
	std::size_t, 
	bool>>
	
	AxiomCallGraphMap;
    
    const
    std::vector<
    std::size_t>
    
    Theorem_UInt64Vec =
    {
    	1585615607, // {"1", "+", "1", "+", "1", "+", "1"}, // (lhs) Prime Composite: 1585615607 //
    	29, // {"4"} // (rhs) Prime Composite: 29 //
    	0, // guid
    	0, // last_guid
    	// begin proofstack
    };
    
    const
    std::vector<
    std::vector<
    std::size_t>>
    
    Axioms_UInt64Vec = 
    {
        // Axiom_0
    	{
    		8303,   // {"1", "+", "1"}, // (lhs) Prime Composite: 8303 //
    		31,     // {"2"} // (rhs) Prime Composite: 31
    		1       // guid
    	},
    
        // Axiom_1
    	{
    		22103,  // {"2", "+", "2"}, // (lhs) Prime Composite: 22103 //
    		29,      // {"4"} // (rhs) Prime Composite: 29 //
    		2       // guid
    	}
    };
    
    /**
    PopulateAxiomCallGraph
    (
        std::unordered_map<
    	/BigInt128_t/
    	std::size_t,
    	std::unordered_map<
    	/BigInt128_t/
    	std::size_t, 
    	bool>>&
    	InAxiomCallGraphMap
    )
    
    Description: Adds qualifying axiom subnet netlists to the outbound route map.
    
    The modulus (%) operator which checks for divisibility requires 40-70 CPU microinstructions
    so it is more efficient to perform this expensive operation once.
    
    Note: The following indirection labels are arbitrary: The chief goal is a standard sytem and method which adequately describes
    the indirection of incoming & outgoing subnets. Reduce : LHS ==> RHS; Expand : LHS <== RHS.
    */
    auto PopulateAxiomCallGraph =
    	[&]
    (
        std::unordered_map<
    	/*BigInt128_t*/
    	std::size_t,
    	std::unordered_map<
    	/*BigInt128_t*/
    	std::size_t, 
    	bool>>&
    	InAxiomCallGraphMap
    )
    {
        __stdtracein__("PopulateAxiomCallGraph");
    	for (const std::vector</*BigInt128_t*/std::size_t>& Axiom_i : Axioms_UInt64Vec)
    	{
    		if
    		(
    		    !InAxiomCallGraphMap[Theorem_UInt64Vec[guid_UInt64]][Axiom_i[guid_UInt64]] &&
    		    (
    		        Theorem_UInt64Vec[LHS] % Axiom_i[LHS] == 0 ||
    		        Theorem_UInt64Vec[LHS] % Axiom_i[RHS] == 0 ||
    		        Theorem_UInt64Vec[RHS] % Axiom_i[LHS] == 0 ||
    		        Theorem_UInt64Vec[RHS] % Axiom_i[RHS] == 0
	            )
    		)
    		{
			    InAxiomCallGraphMap[Theorem_UInt64Vec[guid_UInt64]][Axiom_i[guid_UInt64]] = true;
    
    			__stdlog__({ "InAxiomCallGraphMap[Theorem_UInt64Vec_"+std::to_string(Theorem_UInt64Vec[guid_UInt64])+"][Axiom_"+std::to_string(Axiom_i[guid_UInt64])+"] =", 
    			std::to_string(InAxiomCallGraphMap[Theorem_UInt64Vec[guid_UInt64]][Axiom_i[guid_UInt64]]) });
    		}
    
    		for (const std::vector</*BigInt128_t*/std::size_t>& Axiom_j : Axioms_UInt64Vec)
    		{
    			if (Axiom_i[guid_UInt64] == Axiom_j[guid_UInt64])
    				continue;
    
    			if 
        		(
        		    !InAxiomCallGraphMap[Axiom_i[guid_UInt64]][Axiom_j[guid_UInt64]] &&
        		    (
        		        Axiom_i[LHS] % Axiom_j[LHS] == 0 ||
        		        Axiom_i[LHS] % Axiom_j[RHS] == 0 ||
        		        Axiom_i[RHS] % Axiom_j[LHS] == 0 ||
        		        Axiom_i[RHS] % Axiom_j[RHS] == 0
    	            )
        		)
    			{
			        InAxiomCallGraphMap[Axiom_i[guid_UInt64]][Axiom_j[guid_UInt64]] = true;
    
    				__stdlog__({ "InAxiomCallGraphMap[Axiom_"+std::to_string(Axiom_i[guid_UInt64])+"][Axiom_"+std::to_string(Axiom_j[guid_UInt64])+"] =", 
    				std::to_string(InAxiomCallGraphMap[Axiom_i[guid_UInt64]][Axiom_j[guid_UInt64]]) });
    			}
    		} // end for (...Axiom_j : Axioms_UInt64Vec)
    	} // end for (...Axiom_i : Axioms_UInt64Vec)
    	__stdtraceout__("PopulateAxiomCallGraph");
    };
	
    const auto start_time_chrono = std::chrono::high_resolution_clock::now();
    
	PopulateAxiomCallGraph(AxiomCallGraphMap);

    const auto end_time_chrono = std::chrono::high_resolution_clock::now();
    const auto duration_chrono = std::chrono::duration_cast<std::chrono::nanoseconds>(end_time_chrono - start_time_chrono).count();
    std::cout << "Total Duration (nanoseconds): " << duration_chrono << std::endl;
	
    return EXIT_SUCCESS;
}

//
#include <cstdlib>
#include <iostream>
#include <chrono>
#include <thread>
#include <future>

int main()
{
    bool bStatusReadyFlag {};
    const std::string QED {"Q.E.D."};
    
    auto cb = [](const bool& _bStatusReadyFlag, const std::string& _qed) -> void 
    {
        if (_bStatusReadyFlag)
            std::cout << _qed << std::endl;
    };
    
    auto ReWrite = [](bool& _bStatusReadyFlag, const std::string& _qed, auto&& _cb) -> void
    {
        std::cout << "ReWrite..." << std::endl;
        _bStatusReadyFlag = true;
        if (_cb)
            _cb (_bStatusReadyFlag, _qed);
    };
	
	auto start_time_chrono = std::chrono::high_resolution_clock::now();
	
	auto future = std::async(ReWrite, std::ref(bStatusReadyFlag), std::cref(QED), std::move(cb));
	
	auto end_time_chrono = std::chrono::high_resolution_clock::now();
	auto duration_chrono = std::chrono::duration_cast<std::chrono::nanoseconds>(end_time_chrono - start_time_chrono).count();
	std::cout << "Total Duration (nanoseconds): " << duration_chrono << std::endl;
	
    future.get();
	
	return EXIT_SUCCESS;
}
//
				/*
				if (ProofFoundFlag)
				{
					std::cout << std::endl;
					std::cout << "Proof Found" << std::endl;

					bool lhs_Flag = false;
					for
						(
							const
							std::vector<
							std::string>& Subnet_StdStrVec :
							InTheoremStdStrVec
						)
					{
						if (lhs_Flag)
						{
							std::cout << "= ";
						}

						lhs_Flag = true;

						for (const std::string& Symbol_StdStr : Subnet_StdStrVec)
						{
							std::cout << Symbol_StdStr << " ";
						}
					}

					std::cout << std::endl;

					if (ProofStack_UInt64 < Theorem.size())
					{
						for
							(
								uint64_t ProofStep_UInt64 = ProofStack_UInt64;
								ProofStep_UInt64 < Theorem.size();
								++ProofStep_UInt64
								)
						{
							std::cout << "Axiom_" << Theorem[ProofStep_UInt64] << std::endl;
						}
					}
					std::cout << "Theorem_0000 {" << Theorem[LHS] << ", " << Theorem[RHS] << "}" << std::endl;
					std::cout << std::endl;
					std::cout << "Q.E.D." << std::endl;

					++TotalProofsFound_UInt64;

					if (TotalProofsFound_UInt64 >= MaxAllowedProofs_UInt64)
					{
						QED = true;
						break;
					}

				} else {
					// Retain Partial-proof //
					continue;
				}
				*/
//
				for
					(
						uint64_t ProofStep_UInt64 = ProofStack_UInt64;
						ProofStep_UInt64 < Theorem.size();
						ProofStep_UInt64 += 2
					)
				{/*
					if
					(
						!RewriteInstruction_Map
						[uint64_t { Theorem[ProofStep_UInt64] }] // provide opcode //
						(uint64_t { Theorem[ProofStep_UInt64 + 1] }) // provide Axiom_N //
					)
					{
						ProofFoundFlag = false;
						break;
					}*/

					std::string TempVal {};
					switch (uint64_t{ Theorem[ProofStep_UInt64] })
					{
					case 0x00:
						TempVal = "lhs_reduce via "; break;
					case 0x01:
						TempVal = "lhs_expand via "; break;
					case 0x02:
						TempVal = "rhs_reduce via "; break;
					case 0x03:
						TempVal = "rhs_expand via "; break;
					}
					TempVal += Theorem[ProofStep_UInt64 + 1].str();
					TempAxiomCommitLog_StdStrVec.emplace_back(TempVal);
					std::cout << TempVal << std::endl;
				}

				//OutAxiomCommitLogStdStrVecRef.emplace_back(TempAxiomCommitLog_StdStrVec);
//
				/*
				if 
					(
						!ScopeSatisfied
						(
							TempAxiomCommitLog_StdStrVec, 
							TempProofSteps
						)
					)
				{
					ProofFoundFlag = false;
					break;
				}

				*/
// Add new rewrites to the task queue //
				for (const std::vector<BigInt128_t>& Axiom : Axioms_UInt64Vec)
				{
					if
						(
							Theorem[LHS] % Axiom[LHS] == 0
							/*AxiomCallGraph_Map["lhs_reduce"][Theorem[last_UInt64]][Axiom[guid_UInt64]] == true /* &&
							CallHistory[Theorem[last_UInt64]][Axiom[guid_UInt64]] == false*/
						)
					{/*
						NextRoundCallHistory.emplace
						(
							Theorem[last_UInt64],
							std::unordered_map<BigInt128_t, bool>{ {Axiom[guid_UInt64], true}}
						);*/

						std::vector<BigInt128_t> Theorem_0000{ Theorem };
						Theorem_0000[LHS] = Theorem_0000[LHS] / Axiom[LHS] * Axiom[RHS];
						//Theorem_0000[last_UInt64] = Axiom[guid_UInt64];
						Theorem_0000.emplace_back(0x00); // Push opcode 0x00 onto the proofstack because we performed a _lhs _reduce operation) //
						Theorem_0000.emplace_back(Axiom[guid_UInt64]); // Push the Axiom ID onto the proofstack //
						std::cout << "_reduce Module_0000 via Axiom_" << Axiom[guid_UInt64] << " {" << Theorem_0000[LHS] << ", " << Theorem_0000[RHS] << "}" << std::endl;

						Tasks_Thread.push(Theorem_0000);
					}

					if
						(
							Theorem[LHS] % Axiom[RHS] == 0
							/*AxiomCallGraph_Map["lhs_expand"][Theorem[last_UInt64]][Axiom[guid_UInt64]] == true /*&&
							!CallHistory[Theorem[last_UInt64]][Axiom[guid_UInt64]] == false*/
						)
					{/*
						NextRoundCallHistory.emplace
						(
							Theorem[last_UInt64],
							std::unordered_map<BigInt128_t, bool>{ {Axiom[guid_UInt64], true}}
						);*/

						std::vector<BigInt128_t> Theorem_0001{ Theorem };
						Theorem_0001[LHS] = Theorem_0001[LHS] / Axiom[RHS] * Axiom[LHS];
						//Theorem_0001[last_UInt64] = Axiom[guid_UInt64];
						Theorem_0001.emplace_back(0x01); // Push opcode 0x01 onto the proofstack because we performed a _lhs _expand operation) //
						Theorem_0001.emplace_back(Axiom[guid_UInt64]); // Push the Axiom ID onto the proofstack //
						std::cout << "_expand Module_0001 via Axiom_" << Axiom[guid_UInt64] << " {" << Theorem_0001[LHS] << ", " << Theorem_0001[RHS] << "}" << std::endl;

						Tasks_Thread.push(Theorem_0001);
					}

					if
						(
							Theorem[RHS] % Axiom[LHS] == 0
							/*AxiomCallGraph_Map["rhs_reduce"][Theorem[last_UInt64]][Axiom[guid_UInt64]] == true /*&&
							!CallHistory[Theorem[last_UInt64]][Axiom[guid_UInt64]] == false*/
						)
					{/*
						NextRoundCallHistory.emplace
						(
							Theorem[last_UInt64],
							std::unordered_map<BigInt128_t, bool>{ {Axiom[guid_UInt64], true}}
						);*/

						std::vector<BigInt128_t> Theorem_0002{ Theorem };
						Theorem_0002[RHS] = Theorem_0002[RHS] / Axiom[LHS] * Axiom[RHS];
						//Theorem_0002[last_UInt64] = Axiom[guid_UInt64];
						Theorem_0002.emplace_back(0x02); // Push opcode 0x02 onto the proofstack because we performed a _rhs _reduce operation) //
						Theorem_0002.emplace_back(Axiom[guid_UInt64]); // Push the Axiom ID onto the proofstack //
						std::cout << "_reduce Module_0002 via Axiom_" << Axiom[guid_UInt64] << " {" << Theorem_0002[LHS] << ", " << Theorem_0002[RHS] << "}" << std::endl;

						Tasks_Thread.push(Theorem_0002);
					}

					if
						(
							Theorem[RHS] % Axiom[RHS] == 0
							/*AxiomCallGraph_Map["rhs_expand"][Theorem[last_UInt64]][Axiom[guid_UInt64]] == true /*&&
							!CallHistory[Theorem[last_UInt64]][Axiom[guid_UInt64]] == false*/
							)
					{/*
						NextRoundCallHistory.emplace
						(
							Theorem[last_UInt64],
							std::unordered_map<BigInt128_t, bool>{ {Axiom[guid_UInt64], true}}
						);*/

						std::vector<BigInt128_t> Theorem_0003{ Theorem };
						Theorem_0003[RHS] = Theorem_0003[RHS] / Axiom[RHS] * Axiom[LHS];
						//Theorem_0003[last_UInt64] = Axiom[guid_UInt64];
						Theorem_0003.emplace_back(0x03); // Push opcode 0x03 onto the proofstack because we performed a _rhs _expand operation) //
						Theorem_0003.emplace_back(Axiom[guid_UInt64]); // Push the Axiom ID onto the proofstack //
						std::cout << "_expand Module_0003 via Axiom_" << Axiom[guid_UInt64] << " {" << Theorem_0003[LHS] << ", " << Theorem_0003[RHS] << "}" << std::endl;

						Tasks_Thread.push(Theorem_0003);
					}
					//CallHistory = NextRoundCallHistory;
					std::cout << std::endl;
				} // end for (...Axiom : InAxioms_StdStrVec)
//
		/**
		PopulateAxiomCallGraph
		(
			std::unordered_map<
			std::string,
			std::unordered_map<
			BigInt128_t,
			std::unordered_map<
			BigInt128_t,bool>>>&
			InAxiomCallGraph_Map
		)

		Description: Adds qualifying axiom subnet netlists to the outbound route map.

		The modulus (%) operator which checks for divisibility requires 40-70 CPU microinstructions
		so it is more efficient to perform this expensive operation once.

		Note: The following indirection labels are arbitrary: The chief goal is a standard sytem and method which adequately describes
		the indirection of incoming & outgoing subnets. Reduce : LHS ==> RHS; Expand : LHS <== RHS.
		*/
		auto PopulateAxiomCallGraph =
			[&]
		(
			std::unordered_map<
			std::string,
			std::unordered_map<
			BigInt128_t,
			std::unordered_map<
			BigInt128_t, bool>>>&
			InAxiomCallGraph_Map
		)
		{
			for (const std::vector<BigInt128_t>& Axiom_i : Axioms_UInt64Vec)
			{
				if (Theorem_UInt64Vec[LHS] % Axiom_i[LHS] == 0)
				{
					InAxiomCallGraph_Map.emplace
					(
						"lhs_reduce",
						std::unordered_map<
						BigInt128_t,
						std::unordered_map<
						BigInt128_t, bool>>
						{ {Theorem_UInt64Vec[guid_UInt64], { {Axiom_i[guid_UInt64], true} } }}
					);

					std::cout << "InAxiomCallGraph_Map[\"lhs_reduce\"][Theorem_UInt64Vec[guid_UInt64]][Axiom_i[guid_UInt64]] = " <<
					std::boolalpha << InAxiomCallGraph_Map["lhs_reduce"][Theorem_UInt64Vec[guid_UInt64]][Axiom_i[guid_UInt64]] << std::endl;
				}

				if (Theorem_UInt64Vec[LHS] % Axiom_i[RHS] == 0)
				{
					InAxiomCallGraph_Map.emplace
					(
						"lhs_expand",
						std::unordered_map<
						BigInt128_t,
						std::unordered_map<
						BigInt128_t, bool>>
						{ {Theorem_UInt64Vec[guid_UInt64], { {Axiom_i[guid_UInt64], true} } }}
					);

					std::cout << "InAxiomCallGraph_Map[\"lhs_expand\"][Theorem_UInt64Vec[guid_UInt64]][Axiom_i[guid_UInt64]] = " <<
					std::boolalpha << InAxiomCallGraph_Map["lhs_expand"][Theorem_UInt64Vec[guid_UInt64]][Axiom_i[guid_UInt64]] << std::endl;
				}

				if (Theorem_UInt64Vec[RHS] % Axiom_i[LHS] == 0)
				{
					InAxiomCallGraph_Map.emplace
					(
						"rhs_reduce",
						std::unordered_map<
						BigInt128_t,
						std::unordered_map<
						BigInt128_t, bool>>
						{ {Theorem_UInt64Vec[guid_UInt64], { {Axiom_i[guid_UInt64], true} } }}
					);

					std::cout << "InAxiomCallGraph_Map[\"rhs_reduce\"][Theorem_UInt64Vec[guid_UInt64]][Axiom_i[guid_UInt64]] = " <<
					std::boolalpha << InAxiomCallGraph_Map["rhs_reduce"][Theorem_UInt64Vec[guid_UInt64]][Axiom_i[guid_UInt64]] << std::endl;
				}

				if (Theorem_UInt64Vec[RHS] % Axiom_i[RHS] == 0)
				{
					InAxiomCallGraph_Map.emplace
					(
						"rhs_expand",
						std::unordered_map<
						BigInt128_t,
						std::unordered_map<
						BigInt128_t, bool>>
						{ {Theorem_UInt64Vec[guid_UInt64], { {Axiom_i[guid_UInt64], true} } }}
					);

					std::cout << "InAxiomCallGraph_Map[\"rhs_expand\"][Theorem_UInt64Vec[guid_UInt64]][Axiom_i[guid_UInt64]] = " <<
					std::boolalpha << InAxiomCallGraph_Map["rhs_expand"][Theorem_UInt64Vec[guid_UInt64]][Axiom_i[guid_UInt64]] << std::endl;
				}

				for (const std::vector<BigInt128_t>& Axiom_j : Axioms_UInt64Vec)
				{
					if (Axiom_i[guid_UInt64] == Axiom_j[guid_UInt64])
						continue;

					if (Axiom_i[LHS] % Axiom_j[LHS] == 0)
					{
						InAxiomCallGraph_Map.emplace
						(
							"lhs_reduce",
							std::unordered_map<
							BigInt128_t,
							std::unordered_map<
							BigInt128_t, bool>>
							{ {Axiom_i[guid_UInt64], { {Axiom_j[guid_UInt64], true} } }}
						);

						std::cout << "InAxiomCallGraph_Map[\"lhs_reduce\"][Axiom_i[guid_UInt64]][Axiom_j[guid_UInt64]] = " <<
						std::boolalpha << InAxiomCallGraph_Map["lhs_reduce"][Axiom_i[guid_UInt64]][Axiom_j[guid_UInt64]] << std::endl;
					}

					if (Axiom_i[LHS] % Axiom_j[RHS] == 0)
					{
						InAxiomCallGraph_Map.emplace
						(
							"lhs_expand",
							std::unordered_map<
							BigInt128_t,
							std::unordered_map<
							BigInt128_t, bool>>
							{ {Axiom_i[guid_UInt64], { {Axiom_j[guid_UInt64], true} } }}
						);

						std::cout << "InAxiomCallGraph_Map[\"lhs_expand\"][Axiom_i[guid_UInt64]][Axiom_j[guid_UInt64]] = " <<
						std::boolalpha << InAxiomCallGraph_Map["lhs_expand"][Axiom_i[guid_UInt64]][Axiom_j[guid_UInt64]] << std::endl;
					}

					if (Axiom_i[RHS] % Axiom_j[LHS] == 0)
					{
						InAxiomCallGraph_Map.emplace
						(
							"rhs_reduce",
							std::unordered_map<
							BigInt128_t,
							std::unordered_map<
							BigInt128_t, bool>>
							{ {Axiom_i[guid_UInt64], { {Axiom_j[guid_UInt64], true} } }}
						);

						std::cout << "InAxiomCallGraph_Map[\"rhs_reduce\"][Axiom_i[guid_UInt64]][Axiom_j[guid_UInt64]] = " <<
						std::boolalpha << InAxiomCallGraph_Map["rhs_reduce"][Axiom_i[guid_UInt64]][Axiom_j[guid_UInt64]] << std::endl;
					}

					if (Axiom_i[RHS] % Axiom_j[RHS] == 0)
					{
						InAxiomCallGraph_Map.emplace
						(
							"rhs_expand",
							std::unordered_map<
							BigInt128_t,
							std::unordered_map<
							BigInt128_t, bool>>
							{ {Axiom_i[guid_UInt64], { {Axiom_j[guid_UInt64], true} } }}
						);

						std::cout << "InAxiomCallGraph_Map[\"rhs_expand\"][Axiom_i[guid_UInt64]][Axiom_j[guid_UInt64]] = " <<
						std::boolalpha << InAxiomCallGraph_Map["rhs_expand"][Axiom_i[guid_UInt64]][Axiom_j[guid_UInt64]] << std::endl;
					}
				} // end for (...Axiom_j : Axioms_UInt64Vec)
			} // end for (...Axiom_i : Axioms_UInt64Vec)
		};

		// Populate access lists
		PopulateAxiomCallGraph(AxiomCallGraph_Map);
//
		std::unordered_map<
		uint64_t,
		std::function<
		bool
		(
			uint64_t
		)
		>> RewriteInstruction_Map;

		RewriteInstruction_Map.emplace(
			0x00, // _lhs _reduce opcode
			[&]
		(
			const
			uint64_t
			InGuid_UInt64
		)
		{
			bool ScopeSatisfied_Flag{ true };

			std::vector<
			std::vector<
			std::string>> u{ TempProofSteps.back() };

			std::vector<
			std::vector<
			std::string>> v{ InAxioms_StdStrVec[InGuid_UInt64] };

			if (v[LHS].size() > u[LHS].size())
			{
				ScopeSatisfied_Flag = false;
			}
			else {
				uint64_t jdx_UIint64{};
				for (const std::string val : u[LHS])
				{
					if (val == v[LHS][jdx_UIint64])
					{
						++jdx_UIint64;
					}
				}

				if (jdx_UIint64 != u[LHS].size())
				{
					ScopeSatisfied_Flag = false;
				}
			}

			TempProofSteps.emplace_back(u);

			return ScopeSatisfied_Flag;
		});

		RewriteInstruction_Map.emplace(
			0x01, // _lhs _expand opcode
			[&]
		(
			const
			uint64_t
			InGuid_UInt64
		)
		{
			bool ScopeSatisfied_Flag{ true };

			return ScopeSatisfied_Flag;
		});

		RewriteInstruction_Map.emplace(
			0x02, // _rhs _reduce opcode
			[&]
		(
			const
			uint64_t
		InGuid_UInt64
		)
		{
			bool ScopeSatisfied_Flag{ true };

			return ScopeSatisfied_Flag;
		});

		RewriteInstruction_Map.emplace(
			0x03, // _rhs _expand opcode
			[&]
		(
			const
			uint64_t
			InGuid_UInt64
		)
		{
			bool ScopeSatisfied_Flag{ true };

			return ScopeSatisfied_Flag;
		});
//
void RemoveEmptyStrings(auto& vec)
{
    // Remove empty strings from-, and resize-, the vec.
    vec.erase(
        std::remove_if(
            vec.begin(), 
            vec.end(), 
            [](const std::string& s)
            {
                return s.empty();
            }), vec.end());
}
//
bool TentativeProofVerified
(
    const
    std::vector<
    std::string>&
    Theorem, 
    
    const
    std::vector<
    std::vector<
    std::string>>&
    InTheorem_StdStrVec, 
    
    const
    std::vector<
    std::vector<
    std::vector<
    std::string>>>&
    InAxioms_StdStrVec,
    
    std::vector<
    std::vector<
    std::string>>&
    OutAxiomCommitLog_StdStrVecRef
)
{
  // Clone InTheorem_StdStrVec as OutTheorem_StdStrVec. //
  std::vector<
  std::vector<
  std::vector<
  std::string>>>
  OutTheorem_StdStrVec {InTheorem_StdStrVec};
  
  std::vector<
  std::vector<
  std::string>>
  TempTheorem_StdStrVec {InTheorem_StdStrVec};

  /**
    Loop through Theorem, starting at Theorem[ProofStack_UInt64],
    and read two values from the vector at a time: Theorem[ProofStack_UInt64 + i++],
    Theorem[ProofStack_UInt64 + i++] - 1.
  
    The first value read out, const auto& opcode = Theorem[ProofStack_UInt64 + i++],
    is an opcode whose hexadecimal value may range from 0x00 to 0x03.
  
    The second value read out, const auto& guid = Theorem[ProofStack_UInt64 + i++] - 1,
    is an index into InAxioms_StdStrVec.
  */
  
  uint64_t i {ProofStack_UInt64};
  while (i < Theorem.size()) {
    const auto& opcode = Theorem[i++];
    const auto& guid = Theorem[i++] - 1;

    switch (opcode)
    {
        case 0x00: { // "lhs_reduce" operation
            if (TempTheorem_StdStrVec[LHS].size() < InAxioms_StdStrVec[guid][LHS].size())
                return false;
            uint64_t k {};
            for (uint64_t j = 0; j < TempTheorem_StdStrVec[LHS].size(); j++) {
                if (TempTheorem_StdStrVec[LHS][j] == InAxioms_StdStrVec[guid][LHS][k]) {
                    TempTheorem_StdStrVec[LHS][j] = InAxioms_StdStrVec[guid][RHS][k++];
                }
            }
            TempAxiomCommitLog_StdStrVecRef.emplace_back("lhs_reduce via Axiom_" + guid/*.str()*/ );
            break;
        }
        case 0x01: { // "lhs_expand" operation
          if (TempTheorem_StdStrVec[LHS].size() < InAxioms_StdStrVec[guid][RHS].size())
            return false;
            uint64_t k {};
          for (uint64_t j = 0; j < TempTheorem_StdStrVec[RHS].size(); j++) {
            if (TempTheorem_StdStrVec[RHS][j] == InAxioms_StdStrVec[guid][LHS][k]) {
              TempTheorem_StdStrVec[RHS][j] = InAxioms_StdStrVec[guid][RHS][k++];
            }
          }
          break;
        }
        case 0x02: { // "rhs_reduce" operation
          if (TempTheorem_StdStrVec[RHS].size() < InAxioms_StdStrVec[guid][LHS].size())
            return false;
            uint64_t k {};
          for (uint64_t j = 0; j < TempTheorem_StdStrVec[LHS].size(); j++) {
            if (TempTheorem_StdStrVec[LHS][j] == InAxioms_StdStrVec[guid][RHS][k]) {
              TempTheorem_StdStrVec[LHS][j] = InAxioms_StdStrVec[guid][LHS][k++];
            }
          }
          break;
        }
        case 0x03: { // "rhs_expand" operation
          if (TempTheorem_StdStrVec[RHS].size() < InAxioms_StdStrVec[guid][RHS].size())
            return false;
            uint64_t k {};
          for (uint64_t j = 0; j < TempTheorem_StdStrVec[RHS].size(); j++) {
            if (TempTheorem_StdStrVec[RHS][j] == InAxioms_StdStrVec[guid][RHS][k]) {
              TempTheorem_StdStrVec[RHS][j] = InAxioms_StdStrVec[guid][LHS][k++];
            }
          }
          break;
        }
        default: {
          // Invalid opcode.
          return false;
        }
    } // end switch(opcode)
    OutAxiomCommitLog_StdStrVecRef.emplace_back(TempAxiomCommitLog_StdStrVecRef);
    OutTheorem_StdStrVec.emplace_back(TempTheorem_StdStrVec);
  }

  // If TentativeProofVerified is unable to complete the loop, the algorithm returns false.
  return true;
}
//
bool PeekScopeSatisfied
(
    auto& th,
    
    auto& th_idx, 
    
    const auto& from
)
{
    uint64_t j {};
    const uint64_t I = th.size();
    const uint64_t J = from.size();
    
    for (uint64_t i = th_idx; i < I; ++i)
    {
        if (th[i] == from[j])
        {
            th[i] = "";
            ++j;
            /*
            if (j < J)
            {
                //continue;
            } else {
                break;
            }
            */
        } else {
            break;
        }
    }
    
    return (j == J);
}

bool Rewrite
(
    auto& th, 
    
    const auto& from, 
    
    const auto& to
)
{
    bool bSuccessFlag {};
    
    if (th.size() < from.size())
        return false;
        
    std::unordered_map<std::string, std::string>
    
    end_scope {{"(", ")"}, {"{", "}"}, {"[", "]"}};
    
    std::vector<
    std::string> result {};
        
    uint64_t i {};
    
    for (const auto& val : th )
    {
        auto tmp {result};
        uint64_t k {i};
        
        if (
            val == from[0] /*&& 
            PeekScopeSatisfied
            (tmp, k, from)*/
            ) // &tmp, &k //
        {
            /*
            i = k;
        
            uint64_t j {};
            
            for (const auto& u : tmp)
            {
                if(j < i)
                {
                    result.emplace_back(u);
                } else if (j == i) {
                    for (const auto& u2 : to)
                    {
                        result.emplace_back (u2);
                    }
                }
                ++j;
            }
            */
            result = tmp;
            bSuccessFlag = true;
            std::cout << "Match found";
        } else {
            std::cout << "No Match found" << val << std::endl;
            result.emplace_back (val);
        }
        ++i;
    }
    
    //RemoveEmptyStrings(result);
    
    th = result;
    
    return bSuccessFlag;
}

//
bool _scope_satisfied
(
    const
    std::string&
    etok_lhs,
    
    const
    std::vector<
    std::string>&
    lhs,
    
    const
    uint64_t&
    lhs_idx,
    
    const
    std::vector<
    std::string>&
    rhs,
    
    const
    uint64_t&
    rhs_idx
)
{
    uint64_t i = 1;
    std::unordered_map<std::string, std::string> end_scope{{"(", ")"}, {"{", "}"}, {"[", "]"}};
    bool sat = true;
    if (lhs[lhs_idx] != rhs[rhs_idx]) {
        sat = false;
    } else if (end_scope.find(etok_lhs) != end_scope.end()) {
        if (
            (lhs_idx + i) < lhs.size() && 
            (rhs_idx + i) < rhs.size()
            )
        {
            std::string ltok = lhs[lhs_idx + i];
            std::string rtok = rhs[rhs_idx + i];
            uint64_t I = rhs.size(); // Math.min(lhs.size,rhs.size) //
            const std::string& etok_rhs = end_scope[etok_lhs];
            while (i++ < I) {
                if (ltok != rtok) {
                    sat = false;
                    break;
                }
                if (rtok == etok_rhs) {
                    break;
                }
                ltok = lhs[lhs_idx + i];
                rtok = rhs[rhs_idx + i];
            }
        } else {
            sat = false;
        }
    } // test(etok_lhs) //
    return sat;
}
/*
  vector<string> tokens;

  // Iterate over the tokens.
  for (const auto& token : tokens) {
    // If the token is an equals sign and the compound flag is not set,
    // reset the index.
    if (token == "=" && !COMPOUND) {
      jdx = 0;
    }

    // If the scope is satisfied,
    if (_scope_satisfied(token, me, idx, from, jdx)) {
      // Add the index to the vector of keys.
      vkeys.push_back(idx);

      // If the index is equal to the size of the from array,
      if (++jdx == from.size) {
        // Set the subnetFOUND flag to true.
        _subnetFOUND = true;

        // Iterate over the keys.
        for (const auto& kdx : vkeys) {
          // Add the sub tag to the HTML pre element at the key index.
          tmpHTML.pre[kdx] += _id.addTAG("sub");

          // Set the HTML post element at the key index to null.
          tmpHTML.post[kdx] = nullptr;

          // Set the HTMLR post element at the key index to null.
          tmpHTMLR.post[kdx] = nullptr;

          // Set the Proof element at the key index to null.
          Proof[kdx] = nullptr;

          // If the index is equal to 0,
          if (ii == 0) {
            // Set the HTML post element at the key index to the result of
            // joining the to array with the sub tag.
            tmpHTML.post[kdx] = to.map([](const auto& atok) {
              return (atok + _id.addTAG("sub"));
            }).join(" ");

            // Set the HTMLR post element at the key index to the result of
            // joining the to array with a space.
            tmpHTMLR.post[kdx] = to.join(' ');

            // Set the Proof element at the key index to the result of
            // joining the to array with a space.
            Proof[kdx] = to.join(" ");
          }
        }

        // Reset the index.
        jdx = 0;

        // Clear the vector of keys.
        vkeys.clear();
      }
    }
  }
*/

    bool bRewriteFlag {true};

        if (
            val == from[I] /*&& 
            end_scope.find(val) == end_scope.end()*/
            )
        {
            if (bRewriteFlag)
            {
                i = I;
                bRewriteFlag = false;
                /*
                for (const auto& val2 : to)
                {
                    ++j;
                    result.emplace_back (val2);
                }*/
            }
            ++I;
        } else {
            result.emplace_back (val);
        }
